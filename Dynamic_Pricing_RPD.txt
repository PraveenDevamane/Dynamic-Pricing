RPD — Reinforcement Learning–Based Dynamic Pricing System With Demand Forecasting1. Project TitleDynamic Pricing Optimization using Demand Forecasting and Reinforcement Learning2. ObjectiveThe main objective of this project is to:1. Predict product demand using machine learning based on factors such as price, seasonality, weather, promotion, competitor pricing, and inventory levels.2. Optimize product prices using a Reinforcement Learning (RL) agent that maximizes revenue while following product?specific price constraints.3. Scope of the ProjectIn Scope:- Demand forecasting model (LightGBM / CatBoost)- Data preprocessing and feature engineering- Demand simulator construction- RL environment design- SAC/PPO training for pricing optimization- Product?specific price range enforcementOut of Scope:- Real?time backend deployment- Integration with production POS systems4. Dataset DescriptionDataset contains 76,000+ records with fields:Date, Store ID, Product ID, Category, Region, Inventory Level, Units Sold, Units Ordered, Price, Discount, Weather, Promotion, Competitor Pricing, Seasonality, Epidemic, Demand5. System Architecture5.1 Demand Forecasting ModuleUses LightGBM or CatBoost to predict demand based on contextual and historical features.5.2 Demand SimulatorTrained demand model serves as environment model for RL.5.3 RL EnvironmentState includes product features, competitor price, weather, seasonality, inventory, and demand history.Actions: Continuous price values within allowed range.Reward: Revenue = price ? predicted demand.6. Functional Requirements- Forecast demand accurately- Enforce per?product price limits- Provide optimal price for each timestep- Use demand model as RL simulator7. Non?Functional RequirementsPerformance: Fast training and inferenceScalability: Support multiple stores/productsReliability: Price always within allowed constraintsMaintainability: Modular architecture8. Constraints- Price must remain within min?max historical range per product- Demand must remain non?negative- Inventory limitations must be respected9. Algorithms & ToolsDemand: LightGBM, CatBoost, OptunaRL: SAC, PPO (Stable Baselines3)Tools: Python, Pandas, NumPy, scikit?learn, SB310. Evaluation MetricsDemand Model: RMSE, MAE, R?RL Agent: Total revenue, policy stability, comparison to baselines11. Risks & MitigationOverfitting ? Cross?validationUnrealistic pricing ? Strict price boundsSlow RL training ? Use SAC12. Deliverables- Clean dataset- Demand forecasting model- RL pricing environment- Trained RL policy- Evaluation charts/reports