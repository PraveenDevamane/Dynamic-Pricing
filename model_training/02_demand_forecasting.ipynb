{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Demand Forecasting with LightGBM & Optuna\n",
                "\n",
                "This notebook trains a LightGBM model to predict demand, optimized using Optuna."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
                        "  from .autonotebook import tqdm as notebook_tqdm\n"
                    ]
                }
            ],
            "source": [
                "import pandas as pd\n",
                "import numpy as np\n",
                "import lightgbm as lgb\n",
                "import optuna\n",
                "from sklearn.model_selection import train_test_split\n",
                "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
                "from sklearn.preprocessing import LabelEncoder\n",
                "import pickle\n",
                "\n",
                "%matplotlib inline"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load Data\n",
                "df = pd.read_csv('../data/sales_data.csv')\n",
                "\n",
                "# Feature Engineering\n",
                "df['Date'] = pd.to_datetime(df['Date'])\n",
                "df['Month'] = df['Date'].dt.month\n",
                "df['Day'] = df['Date'].dt.day\n",
                "df['Weekday'] = df['Date'].dt.weekday\n",
                "\n",
                "# Encode Categoricals\n",
                "cat_cols = ['Store ID', 'Product ID', 'Category', 'Region', 'Weather Condition', 'Seasonality', 'Promotion']\n",
                "le_dict = {}\n",
                "for col in cat_cols:\n",
                "    le = LabelEncoder()\n",
                "    df[col] = le.fit_transform(df[col])\n",
                "    le_dict[col] = le\n",
                "\n",
                "# Define Features and Target\n",
                "# We include Inventory Level as per RPD\n",
                "features = ['Store ID', 'Product ID', 'Category', 'Region', 'Inventory Level', \n",
                "            'Price', 'Discount', 'Weather Condition', 'Promotion', \n",
                "            'Competitor Pricing', 'Seasonality', 'Epidemic', 'Month', 'Day', 'Weekday']\n",
                "target = 'Demand'\n",
                "\n",
                "X = df[features]\n",
                "y = df[target]\n",
                "\n",
                "# Split Data\n",
                "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Optuna Hyperparameter Tuning"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[I 2025-11-23 02:07:37,721] A new study created in memory with name: no-name-1149bef0-3d13-44b0-91bd-67d573635208\n",
                        "[I 2025-11-23 02:07:46,324] Trial 0 finished with value: 14.290921466764805 and parameters: {'num_leaves': 66, 'learning_rate': 0.02689967673195379, 'n_estimators': 949, 'max_depth': 11, 'min_child_samples': 41, 'subsample': 0.9475826277044406, 'colsample_bytree': 0.8371863798144796}. Best is trial 0 with value: 14.290921466764805.\n",
                        "[I 2025-11-23 02:07:53,531] Trial 1 finished with value: 7.805335048372081 and parameters: {'num_leaves': 67, 'learning_rate': 0.15063139082926058, 'n_estimators': 955, 'max_depth': 7, 'min_child_samples': 69, 'subsample': 0.7046806782247156, 'colsample_bytree': 0.9036450881412936}. Best is trial 1 with value: 7.805335048372081.\n",
                        "[I 2025-11-23 02:07:54,945] Trial 2 finished with value: 14.764999440779485 and parameters: {'num_leaves': 117, 'learning_rate': 0.23034339661310407, 'n_estimators': 153, 'max_depth': 7, 'min_child_samples': 91, 'subsample': 0.7561333927752518, 'colsample_bytree': 0.689602900241826}. Best is trial 1 with value: 7.805335048372081.\n",
                        "[I 2025-11-23 02:07:59,405] Trial 3 finished with value: 9.286056654324273 and parameters: {'num_leaves': 127, 'learning_rate': 0.23567756284897837, 'n_estimators': 292, 'max_depth': 11, 'min_child_samples': 46, 'subsample': 0.7003942443754113, 'colsample_bytree': 0.6906613539317958}. Best is trial 1 with value: 7.805335048372081.\n",
                        "[I 2025-11-23 02:08:02,331] Trial 4 finished with value: 22.45408848695867 and parameters: {'num_leaves': 41, 'learning_rate': 0.035000678820236476, 'n_estimators': 396, 'max_depth': 13, 'min_child_samples': 38, 'subsample': 0.5490182474576935, 'colsample_bytree': 0.5260147413751564}. Best is trial 1 with value: 7.805335048372081.\n",
                        "[I 2025-11-23 02:08:06,245] Trial 5 finished with value: 15.967382691616294 and parameters: {'num_leaves': 85, 'learning_rate': 0.059762805712343235, 'n_estimators': 300, 'max_depth': 14, 'min_child_samples': 83, 'subsample': 0.7842227738566424, 'colsample_bytree': 0.6328693363599591}. Best is trial 1 with value: 7.805335048372081.\n",
                        "[I 2025-11-23 02:08:08,399] Trial 6 finished with value: 13.172556426458772 and parameters: {'num_leaves': 35, 'learning_rate': 0.14293569468875011, 'n_estimators': 466, 'max_depth': 6, 'min_child_samples': 27, 'subsample': 0.7493549039215117, 'colsample_bytree': 0.8266470287716439}. Best is trial 1 with value: 7.805335048372081.\n",
                        "[I 2025-11-23 02:08:14,538] Trial 7 finished with value: 8.53488075950886 and parameters: {'num_leaves': 81, 'learning_rate': 0.12614934344106082, 'n_estimators': 548, 'max_depth': 13, 'min_child_samples': 21, 'subsample': 0.8810032405538268, 'colsample_bytree': 0.857253790427861}. Best is trial 1 with value: 7.805335048372081.\n",
                        "[I 2025-11-23 02:08:16,132] Trial 8 finished with value: 12.989568890728032 and parameters: {'num_leaves': 86, 'learning_rate': 0.23040305247975348, 'n_estimators': 124, 'max_depth': 12, 'min_child_samples': 82, 'subsample': 0.5643854536347017, 'colsample_bytree': 0.6275321377031751}. Best is trial 1 with value: 7.805335048372081.\n",
                        "[I 2025-11-23 02:08:18,878] Trial 9 finished with value: 24.11588751838821 and parameters: {'num_leaves': 93, 'learning_rate': 0.032300860473131604, 'n_estimators': 292, 'max_depth': 7, 'min_child_samples': 63, 'subsample': 0.6902222295947035, 'colsample_bytree': 0.6504688724275646}. Best is trial 1 with value: 7.805335048372081.\n",
                        "[I 2025-11-23 02:08:31,866] Trial 10 finished with value: 8.458213133794978 and parameters: {'num_leaves': 150, 'learning_rate': 0.17700097688903618, 'n_estimators': 988, 'max_depth': 9, 'min_child_samples': 66, 'subsample': 0.6192535481153099, 'colsample_bytree': 0.999939717521591}. Best is trial 1 with value: 7.805335048372081.\n",
                        "[I 2025-11-23 02:08:44,460] Trial 11 finished with value: 8.275921935967041 and parameters: {'num_leaves': 146, 'learning_rate': 0.18327647753199366, 'n_estimators': 952, 'max_depth': 9, 'min_child_samples': 62, 'subsample': 0.6301091793694646, 'colsample_bytree': 0.9996585061082707}. Best is trial 1 with value: 7.805335048372081.\n",
                        "[I 2025-11-23 02:08:49,921] Trial 12 finished with value: 7.850763494271336 and parameters: {'num_leaves': 57, 'learning_rate': 0.29851474745025613, 'n_estimators': 776, 'max_depth': 9, 'min_child_samples': 70, 'subsample': 0.63179368752717, 'colsample_bytree': 0.9990353579811234}. Best is trial 1 with value: 7.805335048372081.\n",
                        "[I 2025-11-23 02:08:52,660] Trial 13 finished with value: 8.252335695014475 and parameters: {'num_leaves': 53, 'learning_rate': 0.28976576066216153, 'n_estimators': 762, 'max_depth': 5, 'min_child_samples': 75, 'subsample': 0.505025093871931, 'colsample_bytree': 0.9226009780685549}. Best is trial 1 with value: 7.805335048372081.\n",
                        "[I 2025-11-23 02:08:55,381] Trial 14 finished with value: 13.489439428068218 and parameters: {'num_leaves': 23, 'learning_rate': 0.09719690827098182, 'n_estimators': 757, 'max_depth': 8, 'min_child_samples': 99, 'subsample': 0.8399126969782666, 'colsample_bytree': 0.9262034988464359}. Best is trial 1 with value: 7.805335048372081.\n",
                        "[I 2025-11-23 02:09:01,270] Trial 15 finished with value: 8.2773412078354 and parameters: {'num_leaves': 63, 'learning_rate': 0.2728812551655175, 'n_estimators': 776, 'max_depth': 9, 'min_child_samples': 54, 'subsample': 0.6422291383875568, 'colsample_bytree': 0.910180674591849}. Best is trial 1 with value: 7.805335048372081.\n",
                        "[I 2025-11-23 02:09:04,573] Trial 16 finished with value: 15.643739496276456 and parameters: {'num_leaves': 103, 'learning_rate': 0.09530470817045031, 'n_estimators': 858, 'max_depth': 5, 'min_child_samples': 73, 'subsample': 0.6913879777120104, 'colsample_bytree': 0.7802033534601647}. Best is trial 1 with value: 7.805335048372081.\n",
                        "[I 2025-11-23 02:09:10,194] Trial 17 finished with value: 8.173438143972302 and parameters: {'num_leaves': 71, 'learning_rate': 0.18481538206996312, 'n_estimators': 667, 'max_depth': 7, 'min_child_samples': 53, 'subsample': 0.8201728076126666, 'colsample_bytree': 0.9541288392732634}. Best is trial 1 with value: 7.805335048372081.\n",
                        "[I 2025-11-23 02:09:14,328] Trial 18 finished with value: 8.34579856229642 and parameters: {'num_leaves': 47, 'learning_rate': 0.25965469258350815, 'n_estimators': 645, 'max_depth': 10, 'min_child_samples': 80, 'subsample': 0.6124960917160238, 'colsample_bytree': 0.8765950636172906}. Best is trial 1 with value: 7.805335048372081.\n",
                        "[I 2025-11-23 02:09:17,702] Trial 19 finished with value: 7.840824105359702 and parameters: {'num_leaves': 23, 'learning_rate': 0.2068697963055061, 'n_estimators': 837, 'max_depth': 15, 'min_child_samples': 11, 'subsample': 0.9888620428080516, 'colsample_bytree': 0.9628136948849558}. Best is trial 1 with value: 7.805335048372081.\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Best trial: {'num_leaves': 67, 'learning_rate': 0.15063139082926058, 'n_estimators': 955, 'max_depth': 7, 'min_child_samples': 69, 'subsample': 0.7046806782247156, 'colsample_bytree': 0.9036450881412936}\n"
                    ]
                }
            ],
            "source": [
                "def objective(trial):\n",
                "    params = {\n",
                "        'objective': 'regression',\n",
                "        'metric': 'rmse',\n",
                "        'verbosity': -1,\n",
                "        'boosting_type': 'gbdt',\n",
                "        'num_leaves': trial.suggest_int('num_leaves', 20, 150),\n",
                "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3),\n",
                "        'n_estimators': trial.suggest_int('n_estimators', 100, 1000),\n",
                "        'max_depth': trial.suggest_int('max_depth', 5, 15),\n",
                "        'min_child_samples': trial.suggest_int('min_child_samples', 10, 100),\n",
                "        'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n",
                "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),\n",
                "    }\n",
                "    \n",
                "    model = lgb.LGBMRegressor(**params)\n",
                "    model.fit(X_train, y_train)\n",
                "    preds = model.predict(X_test)\n",
                "    rmse = np.sqrt(mean_squared_error(y_test, preds))\n",
                "    return rmse\n",
                "\n",
                "# Run Optimization\n",
                "study = optuna.create_study(direction='minimize')\n",
                "study.optimize(objective, n_trials=20) # 20 trials for speed, increase for better results\n",
                "\n",
                "print('Best trial:', study.best_trial.params)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Train Best Model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "RMSE: 7.805335048372081\n",
                        "MAE: 5.066140436220698\n",
                        "R2: 0.9724143895810476\n"
                    ]
                }
            ],
            "source": [
                "best_params = study.best_trial.params\n",
                "best_params['objective'] = 'regression'\n",
                "best_params['metric'] = 'rmse'\n",
                "\n",
                "final_model = lgb.LGBMRegressor(**best_params)\n",
                "final_model.fit(X_train, y_train)\n",
                "\n",
                "y_pred = final_model.predict(X_test)\n",
                "\n",
                "print(\"RMSE:\", np.sqrt(mean_squared_error(y_test, y_pred)))\n",
                "print(\"MAE:\", mean_absolute_error(y_test, y_pred))\n",
                "print(\"R2:\", r2_score(y_test, y_pred))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Save Model and Encoders"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Model and encoders saved.\n"
                    ]
                }
            ],
            "source": [
                "with open('demand_model_lgbm.pkl', 'wb') as f:\n",
                "    pickle.dump(final_model, f)\n",
                "\n",
                "with open('label_encoders.pkl', 'wb') as f:\n",
                "    pickle.dump(le_dict, f)\n",
                "    \n",
                "print(\"Model and encoders saved.\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.13.3"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
